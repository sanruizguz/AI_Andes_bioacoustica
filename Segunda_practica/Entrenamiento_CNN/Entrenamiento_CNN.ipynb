{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgVZccPTQ7na"
   },
   "source": [
    "\n",
    "# Entrenamiento y evaluación de un detector automatico de cantos basado en CNN con OpenSoundscape\n",
    "\n",
    "### *Santiago Ruiz Guzman - Kitzes Lab, University of Pittsburgh*\n",
    "\n",
    "\n",
    "Este tutorial lo guiara durante el entrenamiento y evaluacion de un clasificador con redes neuronales convolucionales (CNNs) para identificar vocalizaciones utilizando el paquete OpenSoundscape python.\n",
    "\n",
    "Hay más tutoriales disponibles en el sitio web OpenSoundscape relacionados con el analisis de audio y espectrogramas o el uso de otro algoritmo de procesamiento de señales para detectar vocalizaciones.\n",
    "\n",
    " http://opensoundscape.org/en/latest/\n",
    "\n",
    "\n",
    "Primero necesitamos instalar opensoundscape y sus dependencias. Siga el proceso de instalacion en la documentacion segun sea el caso https://opensoundscape.org/en/latest/installation/mac_and_linux.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33gWgU_8EmZc"
   },
   "source": [
    "A continuación, cambie la ruta de la carpeta donde se encuentran los datos de la practica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5RbBYYAPOtDf"
   },
   "outputs": [],
   "source": [
    "folder='/Users/santiagoruiz/Documents/AI_Andes/Sesiones_practicas/Segunda_practica/Entrenamiento_CNN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fe2e5sW0S2du"
   },
   "source": [
    "### Paquetes y funciones necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lAZlG9WsOvI8"
   },
   "outputs": [],
   "source": [
    "import opensoundscape\n",
    "from opensoundscape import CNN\n",
    "import opensoundscape.ml\n",
    "from opensoundscape.preprocess.preprocessors import SpectrogramPreprocessor\n",
    "from opensoundscape.ml.datasets import AudioSplittingDataset\n",
    "from opensoundscape import Audio, Spectrogram\n",
    "from opensoundscape.preprocess.actions import Action\n",
    "from opensoundscape.data_selection import resample\n",
    "from opensoundscape.ml.cnn import load_model\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import subprocess\n",
    "from glob import glob\n",
    "import sklearn\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "plt.rcParams['figure.figsize']=[15,5]\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Configurar 'seed' aleatoria para garantizar reproducibilidad\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNI0VXN_FKS9"
   },
   "source": [
    "Ahora vamos a definir algunas funciones que utilizaremos en el taller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vKiEo5HO_cAm"
   },
   "outputs": [],
   "source": [
    "# Funcion para leer los archivos WAV de entrenamiento\n",
    "def read_samples(path,label):\n",
    "    list_pos = []\n",
    "    for filename in os.scandir(path):\n",
    "        if filename.is_file():\n",
    "            absolute = os.path.abspath(filename.path)\n",
    "            list_pos.append(absolute)\n",
    "    pos_df = pd.DataFrame(list_pos, columns=['file_name'])\n",
    "    index_pos = pd.DataFrame(index=pos_df['file_name'])\n",
    "    index_pos['boana'] = label\n",
    "    return index_pos\n",
    "\n",
    "# Graficar curvas de perdida\n",
    "def plot_scatter(trained_model, title):\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    plt.scatter(trained_model.loss_hist.keys(),trained_model.loss_hist.values(),linewidth=2,edgecolors='w')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.tight_layout()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Graficar histogramas con puntajes de deteccion por clase\n",
    "def plot_testing_hist (model_output,testing_df,title):\n",
    "    first_column_list = model_output.iloc[:, 0].tolist()\n",
    "    testing_df['scores']=first_column_list\n",
    "    boana_pos = testing_df[testing_df['labels'] == True]\n",
    "    boana_neg = testing_df[testing_df['labels'] == False]\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    plt.hist(boana_pos['scores'], bins=20, alpha=0.5, label='True')\n",
    "    plt.hist(boana_neg['scores'], bins=20, alpha=0.5, label='False')\n",
    "    plt.xlabel('Detection score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUXN_2rnSXUy"
   },
   "source": [
    "\n",
    "# Entrenar un clasificador basado en CNN para *Boana faber*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iK_f0P4BP9Xl"
   },
   "source": [
    "# Como puedo representar un archivo de audio?\n",
    "\n",
    "Durante el entrenamiento de un clasificador de cantos se utilizan archivos de sonido en diferentes formatos. A continuación encontrará varias funciones para cargar los cantos de su conjunto de datos directamente desde python (Compruebe https://opensoundscape.org/en/latest/tutorials/audio.html#Load-audio-files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "bVG_ayxAP8kv",
    "outputId": "f304a691-766d-4931-f2ac-1b9beca43b02"
   },
   "outputs": [],
   "source": [
    "# Con OpenSoundscape tu puedes cargar archivos WAV como un objeto de audio\n",
    "audio_path= folder + '/Testing/1_pos_INCT20955_20191011_214500_28_31.wav'\n",
    "audio_object = Audio.from_file(audio_path)\n",
    "\n",
    "# Dale click al boton de reproducir para escuchar los audios\n",
    "audio_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1uKI0N-kgtrW",
    "outputId": "7764cca7-80d2-4eb1-dcea-9b084245d87e"
   },
   "outputs": [],
   "source": [
    "# Verifiquemos los metadatos de los audios\n",
    "audio_object.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "cMa7asS7WmhL",
    "outputId": "8138e8c2-0f6c-411b-bb3d-e340b776b243"
   },
   "outputs": [],
   "source": [
    "# Grafica el oscilograma\n",
    "plt.plot(audio_object.samples)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "-G3V_8bqRvqI",
    "outputId": "dd6583d9-6761-42cf-d854-fc0b717a24df"
   },
   "outputs": [],
   "source": [
    "# Grafica el espectrograma\n",
    "spectrogram_object = Spectrogram.from_audio(audio_object)\n",
    "spectrogram_object.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RuapbhE3bc6n"
   },
   "source": [
    "## Construyamos el set de entrenamiento\n",
    "\n",
    "En este ejercicio vamos a implementar un clasificador binario. Para ello es necesario crear un conjunto de entrenamiento con muestras de audio de las clases de interés.\n",
    "\n",
    "OpenSoundscape también permite construir un conjunto de entrenamiento a partir de archivos de anotación de Raven, esta forma se recomienda con el fin de evitar la creación de archivos duplicados (https://opensoundscape.org/en/latest/tutorials/annotations.html#Load-multiple-Raven-annotation-tables).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "Q3hNb_oXd3RV",
    "outputId": "1c8caff7-3b12-4482-cbd7-2326dad27f64"
   },
   "outputs": [],
   "source": [
    "# Carpeta donde las grabaciones de la primera clase estan guardadas\n",
    "positive=folder+'/Training/BOAFAB_Baseline'\n",
    "\n",
    "list_pos=[] # Crea una lista vacia\n",
    "for filename in os.scandir(positive):   # Revisa todas las rutas al interior de la carpeta donde los WAVs estan guardados\n",
    "    absolute=os.path.abspath(filename)  # Obten las rutas absoluta de cada grabacion\n",
    "    list_pos.append(absolute)           # Guarda todas las rutas en una lista\n",
    "\n",
    "# Crea una dataframe con la lista\n",
    "pos_df = pd.DataFrame(list_pos,columns=['file_name'])\n",
    "\n",
    "# Crear un nuevo dataframe con los nombres de archivo de la tabla anterior como el índice, para este modelo, las rutas wavs NECESITA ser el índice, no sólo una columna normal\n",
    "index_pos = pd.DataFrame(index=pos_df['file_name'])\n",
    "index_pos['boana'] = \"1\" # Crea una columna con 1 representando la presencia de la especie objetivo\n",
    "index_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "HB15sVDv2FjT",
    "outputId": "46620261-eeda-4936-d870-94ba32a2f18f"
   },
   "outputs": [],
   "source": [
    "# Carpeta donde las grabaciones negativas estan guardadas\n",
    "negatives_path=folder+'/Training/OTHER'\n",
    "index_neg=read_samples(negatives_path,\"0\")\n",
    "\n",
    "dataset_size=200 #@param\n",
    "index_pos=index_pos.head(dataset_size)\n",
    "index_neg=index_neg.head(dataset_size)\n",
    "\n",
    "frames = [index_pos, index_neg]\n",
    "label = pd.concat(frames)\n",
    "\n",
    "label[\"boana\"] = pd.to_numeric(label[\"boana\"])\n",
    "label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiQf3hK_GIVI"
   },
   "source": [
    "## Parte el set de datos entre el set de entrenamiento y validacion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSGnq32x8pz_"
   },
   "source": [
    "Teniendo en cuenta los múltiples parámetros que podemos ajustar en un clasificador, es importante establecer un subconjunto de llamadas anotadas para ayudar al modelo a saber lo bueno que es para hacer clasificaciones precisas. Este subconjunto de llamadas anotadas (diferentes de las del conjunto de entrenamiento) se denomina conjunto de validación. Dependiendo del número de llamadas anotadas disponibles, el conjunto de validación suele estar formado por el 20% de las cantos por clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNbOStLS9_La",
    "outputId": "ab9d1bc0-3142-40e9-fde0-6df4bac66749"
   },
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(label, # Dataframe con las rutas para ambas clases\n",
    "                                      test_size=0.2, # Proporción de grabaciones asignadas en el conjunto de validación (20% en este caso)\n",
    "                                      random_state=0) # Número fijo significa que la división «aleatoria» será exactamente la misma cada vez que la ejecutemos\n",
    "\n",
    "print(f\"Set de entrenamiento con {len(train_df)} cantos  y set de validacion con {len(valid_df)} cantos\")\n",
    "print(f\"Set de entrenamiento con  {len(train_df)} cantos  y set de validacion con {len(valid_df)} cantos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2VqkTDaZ92z"
   },
   "source": [
    "## Selecciona una arquitectura para un clasificador\n",
    "\n",
    "Elegir la arquitectura adecuada (número, tipos y dimensiones de las capas dentro de la CNN) para una CNN es un paso importante en el desarrollo de un clasificador acústico. Aunque es posible construir un clasificador desde cero (estableciendo distintas combinaciones de capas), la forma más habitual de construir clasificadores acústicos es utilizando una red preentrenada, proceso conocido como aprendizaje por transferencia.\n",
    "\n",
    "En este caso, tanto la arquitectura como los pesos del clasificador se basarán en la ResNET18, una popular red preentrenada entrenada en ImageNET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vt2UYvTqZ2xv",
    "outputId": "e5bc4625-3955-49a3-c1fe-493d7a77cddf"
   },
   "outputs": [],
   "source": [
    "classes = label.columns\n",
    "architecture= 'resnet18' #@param\n",
    "baseline = CNN(architecture,     # Red pre entrenada\n",
    "            classes,             # El numero de clases\n",
    "            sample_duration=3.0) # Duracion en segundos de cada grabacion\n",
    "\n",
    "# Miremos la arquitectura de la ResNET18\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1I2QEcSKMzU0",
    "outputId": "932f839f-4fe7-481f-d2f4-8b1320a66436"
   },
   "outputs": [],
   "source": [
    "# Pretrained networks available in OPSO\n",
    "opensoundscape.ml.cnn_architectures.list_architectures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0u5Ag-f8p0A"
   },
   "source": [
    "# Conoce al preprocesador\n",
    "\n",
    "En este punto, ya hemos seleccionado el conjunto de datos para los set de entrenamiento y validación, así como la arquitectura para nuestro clasificador. Sin embargo, como puede verse a continuación, cada una de las llamadas de nuestro conjunto de datos debe transformarse en otras estructuras de datos para poder ser interpretada por la CNN. Empezando por un archivo .wav, cada llamada se convertirá en un espectrograma y, finalmente, en un tensor, que es básicamente un vector que contiene la información del espectrograma.\n",
    "\n",
    "Mientras cada archivo .wav pasa por este proceso, es posible establecer múltiples características para mejorar la generalización del modelo. Esto comienza con cambios en la configuración del espectrograma e incluye la creación de grabaciones «falsas» con ligeras modificaciones, lo que se conoce como aumento de datos.\n",
    "\n",
    "Hablaremos de ello más adelante. Por ahora, permítame presentarle la forma en que OpenSoundscape visualiza el preprocesador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2WykGr078p0A",
    "outputId": "5f399970-cf28-4b24-bda2-a62e0139e332"
   },
   "outputs": [],
   "source": [
    "# OPSO incluye alguna de las acciones de aumentacion de datos, ignoremolas por ahora\n",
    "baseline.preprocessor.pipeline.add_noise.bypass=True\n",
    "baseline.preprocessor.pipeline.time_mask.bypass=True\n",
    "baseline.preprocessor.pipeline.bandpass.bypass=True\n",
    "baseline.preprocessor.pipeline.frequency_mask.bypass=True\n",
    "baseline.preprocessor.pipeline.random_affine.bypass=True\n",
    "baseline.preprocessor # Despliega el preprocesador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lqedp7F8p0A"
   },
   "source": [
    "# Introduzcamos el set de evaluacion\n",
    "\n",
    "Un buen conjunto de evaluación es clave para el desarrollo de cualquier clasificador automático. Debe incluir cantos nuevos (no presentes en el conjunto de entrenamiento o evaluación) de todas las clases, a ser posible con la mayor variación posible entre ellas.\n",
    "\n",
    "Además de las métricas tradicionales, la comparación entre las puntuaciones de detección del conjunto de evaluación es muy útil para conocer el grado de generalización entre múltiples modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista los archivos WAV en la carpeta de evaluacion\n",
    "testing_list=sorted(glob(folder + '/Testing/*.wav'))\n",
    "\n",
    "len(testing_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "_RxS--hm8p0A",
    "outputId": "61e86ff3-fdb9-40ec-87e3-83ba5ad8e6fc"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Columnas con las etiquetas del set de evaluacion\n",
    "testing_labels = [True] * 100 + [False] * 100\n",
    "# Dataframe final\n",
    "testing_df = pd.DataFrame({'paths': testing_list, 'labels': testing_labels})\n",
    "testing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkhFNlbWP-FT"
   },
   "source": [
    "# Entrena (y evalua) el modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Enmi0u5C8p0A"
   },
   "source": [
    "Con el preprocesador listo, es hora del paso más crucial del proceso: entrenar el modelo. En este paso, llamaremos tanto al conjunto de entrenamiento como al conjunto de validación que hemos creado. Definiremos una ruta en la que se almacenarán todos los modelos (con extensión .model) y tendremos que definir hiperparámetros importantes como el número de épocas y el tamaño del lote.\n",
    "\n",
    "Este es el paso del proceso que más tiempo consume. Dependiendo del tamaño del conjunto de datos, la complejidad de la arquitectura de la CNN y los valores de los hiperparámetros (especialmente el número de épocas), puede llevar horas. Por eso es importante hacer un seguimiento de los ajustes que utilizamos en cada sesión de entrenamiento. Para ello, podemos utilizar programas como Weights and Biases (https://opensoundscape.org/en/latest/tutorials/train_cnn.html#Set-up-WandB-model-logging) o Neptune (https://neptune.ai/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder + \"/Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "aajj0WAkf1wP",
    "outputId": "7ead4f01-86d4-498b-c89c-5fa5c56793ee"
   },
   "outputs": [],
   "source": [
    "# Usa el siguiente codigo para correr la funcion de entrenamiento\n",
    "\n",
    "history= baseline.train(\n",
    "    train_df=train_df,       # Set de entrenamiento\n",
    "    validation_df=valid_df,  # Set de validacion\n",
    "    save_path= folder + \"/Model\", # Ruta donde los modelos van a ser guardados\n",
    "    epochs= 10,            # Numero de epocs\n",
    "    batch_size= 32,        # Tamaño de lote\n",
    "    #save_interval=20,     # Guarda un nuevo modelo canda X epochs (El mejor modelos siempre se guarda)\n",
    "    num_workers=0\n",
    ")\n",
    "plot_scatter(baseline,\"Baseline\")\n",
    "\n",
    "baseline_test = baseline.predict(testing_list)\n",
    "plot_testing_hist(baseline_test,testing_df,\"Baseline model separability\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0iVSpGlso8a"
   },
   "source": [
    "# 3.1. Datos y preprocesamiento\n",
    "# 3.1.1. Dataset\n",
    "\n",
    "El tamaño del conjunto de entrenamiento importa mucho; un clasificador no puede aprender una variación que nunca se le ha mostrado. Además, en muchos casos hay poca variación entre clases.\n",
    "\n",
    "\n",
    "# 3.1.1.1. Balance de dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuHRyu2sAgyN"
   },
   "source": [
    "#  Entrena el modelo con un set de entrenamiento desbalanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IYOX6quOvLzw"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Remueve la mitad de los cantos positivos (clase BOANA)\n",
    "indices = label[label['boana'] == 1].index\n",
    "np.random.seed(42)\n",
    "label_unbalanced = label.drop(np.random.choice(indices, size=len(indices) // 2, replace=False))\n",
    "\n",
    "# Divide el dataset mientras entrenamiento y evaluacion\n",
    "train_set, valid_set = train_test_split(label_unbalanced, test_size=0.2,random_state=0)\n",
    "\n",
    "print(f\"El numero de cantos en el set balanceado es:\")\n",
    "print(label['boana'].value_counts())\n",
    "print()\n",
    "print(f\"El numero de cantos en el set desbalanceado es:\")\n",
    "print(label_unbalanced['boana'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ooXk1qPyy3qF"
   },
   "outputs": [],
   "source": [
    "unbalanced = CNN('resnet18',classes=list(train_set.columns),sample_duration=3.0) # Create the CNN object\n",
    "\n",
    "history = unbalanced.train(train_df=train_set, validation_df=valid_set,\n",
    "                           save_path= folder + \"/Model\",\n",
    "                           epochs= 10,batch_size= 32, num_workers=0)\n",
    "\n",
    "plot_scatter(baseline,\"Baseline\")\n",
    "\n",
    "\n",
    "plot_scatter(unbalanced, title=\"Unbalanced model loss curve\")\n",
    "\n",
    "# Obten las predicciones y grafica los histogramas\n",
    "unbalanced_test = unbalanced.predict(testing_list)\n",
    "plot_testing_hist(unbalanced_test,testing_df,\" Unbalanced model separability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Szu1e7OHs5dV"
   },
   "source": [
    "# Remuestrea el sets de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dBXTcG9Gs4z0"
   },
   "outputs": [],
   "source": [
    "positives=200\n",
    "negatives=100\n",
    "index_pos=index_pos.head(positives)\n",
    "index_neg=index_neg.head(negatives)\n",
    "frames = [index_pos, index_neg]\n",
    "label = pd.concat(frames)\n",
    "label[\"boana\"] = pd.to_numeric(label[\"boana\"])\n",
    "\n",
    "train_set, valid_set = train_test_split(label,test_size=0.2,random_state=0)\n",
    "\n",
    "# Sobremuestreo (repetir muestras) para que todas las clases tengan x muestras\n",
    "balanced_train_set = resample(train_df,n_samples_per_class=200,random_state=0)\n",
    "print(f\"Set de entrenamiento remuestreado con  {len(balanced_train_set)} cantos\")\n",
    "\n",
    "resampled = CNN('resnet18',classes=list(balanced_train_set.columns),sample_duration=3.0)\n",
    "\n",
    "history = resampled.train(train_df=balanced_train_set, validation_df=valid_set,\n",
    "                          save_path= folder +\"/Model\",\n",
    "                       epochs= 10,batch_size= 32, num_workers=0)\n",
    "\n",
    "plot_scatter(resampled, title=\"Resampled model loss curve\")\n",
    "\n",
    "# Obten las predicciones y grafica los histogramas\n",
    "resampled_test = resampled.predict(testing_list)\n",
    "plot_testing_hist(resampled_test,testing_df,\" Resampled model separability\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jreRuL48QN1N"
   },
   "source": [
    "\n",
    "# 3.1.1.2. Origen de set de datos\n",
    "\n",
    "# Modelo entrenado con set de datos subrepresentado geograficamente\n",
    "\n",
    "La representatividad importa, la generalización del modelo se pondrá a prueba cuando ejecute su modelo en grabaciones de ARUs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ybLJFPXRKvvL"
   },
   "outputs": [],
   "source": [
    "# Crear un nuevo conjunto de entrenamiento con grabaciones de una única ubicación (basado en Canas et al., 2023)\n",
    "\n",
    "tar_p=folder+'/Training/BOAFAB_Location'\n",
    "tar_n=folder+'/Training/OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JPXEHC2nQOey"
   },
   "outputs": [],
   "source": [
    "index_n=read_samples(tar_n,\"0\")\n",
    "index_p=read_samples(tar_p,\"1\")\n",
    "\n",
    "frames = [index_p, index_n]\n",
    "tar_label = pd.concat(frames)\n",
    "\n",
    "tar_label[\"boana\"] = pd.to_numeric(tar_label[\"boana\"])\n",
    "tar_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHlrBsUm00ZF"
   },
   "outputs": [],
   "source": [
    "train_set, valid_set = train_test_split(tar_label,test_size=0.2,random_state=0)\n",
    "targeted = CNN('resnet18',classes=list(balanced_train_set.columns),sample_duration=3.0)\n",
    "\n",
    "\n",
    "history = targeted.train(train_df=train_set, validation_df=valid_set,save_path= folder+\"/Model\",\n",
    "                       epochs= 10,batch_size= 32, num_workers=0)\n",
    "\n",
    "# Obten las predicciones y grafica los histogramas\n",
    "targeted_test = targeted.predict(testing_list)\n",
    "plot_testing_hist(targeted_test,testing_df,\" Targeted model separability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afBtyUy_4XGl"
   },
   "source": [
    "# 3.1.2. Preprocesamiento\n",
    "# 3.1.2.1. Caracteristicas del espectrogramas\n",
    "# Preprocesador con tamaño de ventana \"incorrecto\" (resolucion temporal vs espectral)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-r-U1oVV4Xx3"
   },
   "outputs": [],
   "source": [
    "from opensoundscape import AudioFileDataset, SpectrogramPreprocessor\n",
    "from opensoundscape.preprocess.utils import show_tensor\n",
    "\n",
    "spec_pre=SpectrogramPreprocessor(sample_duration=3)\n",
    "dataset = AudioFileDataset(label,spec_pre)\n",
    "dataset.bypass_augmentations=True\n",
    "\n",
    "# Cambia el tamaño de ventana\n",
    "window_size=1000 #@param\n",
    "\n",
    "# Ejemplo\n",
    "dataset.preprocessor.pipeline.to_spec.params.window_samples = window_size\n",
    "show_tensor(dataset[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52XMafsY8p0C"
   },
   "outputs": [],
   "source": [
    "# Hagamos la CNN y cambia el tamaño de ventana\n",
    "window = CNN('resnet18',classes=list(train_set.columns),sample_duration=3.0)\n",
    "window.preprocessor.pipeline.to_spec.params.window_samples = window_size\n",
    "window.preprocessor.pipeline.to_spec.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sy33KPL58p0C"
   },
   "outputs": [],
   "source": [
    "# Carga el modelo de entrenamiento y evaluacion\n",
    "\n",
    "history = window.train(train_df=train_set, validation_df=valid_set,save_path= folder + \"/Model\",\n",
    "                       epochs= 10,batch_size= 32, num_workers=0)\n",
    "\n",
    "plot_scatter(window, title=\"Window model loss curve\")\n",
    "\n",
    "# Obten las predicciones y grafica los histogramas\n",
    "window_test = window.predict(testing_list)\n",
    "plot_testing_hist(window_test,testing_df,\"Window model separability\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9tLtdE38p0C"
   },
   "source": [
    "# Preprocesamiento with filtro de bajo paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "myppWqPG8p0G"
   },
   "outputs": [],
   "source": [
    "# Asi es como añadimos un filtro de banda\n",
    "dataset.preprocessor.pipeline.bandpass.set(min_f=2000,max_f=4000)\n",
    "\n",
    "print('Tensor incluyendo el filtro de banda')\n",
    "show_tensor(dataset[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TRln1iFU8p0H"
   },
   "outputs": [],
   "source": [
    "# Añade filtro de banda\n",
    "bandpass = CNN('resnet18',classes=list(train_set.columns),sample_duration=3.0) # Create the CNN\n",
    "bandpass.preprocessor.pipeline.bandpass.set(min_f=2000,max_f=4000)\n",
    "bandpass.preprocessor.pipeline.bandpass.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xetLI6tO8p0H"
   },
   "outputs": [],
   "source": [
    "# Entrenamiento y evaluacion del modelo\n",
    "history = bandpass.train(train_df=train_set, validation_df=valid_set,save_path= folder +\"/Model\",\n",
    "                       epochs= 10,batch_size= 32, num_workers=0)\n",
    "\n",
    "plot_scatter(bandpass, title=\"Bandpass model loss curve\")\n",
    "\n",
    "# Obten las predicciones y grafica los histogramas\n",
    "bandpass_test = bandpass.predict(testing_list)\n",
    "plot_testing_hist(bandpass_test,testing_df,\"bandpass model separability\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVtLSa6rRhrZ"
   },
   "source": [
    "# 3.1.2.2. Aumentacion de datos\n",
    "\n",
    "Intenta incrementar la generalizacion del modelo evitando aumentacion de datos destructiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXeJKiW1IqFw"
   },
   "source": [
    "# Preprocesador con aumentacion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Auzsdw8S9Lmo"
   },
   "outputs": [],
   "source": [
    "# Añade la aumentacion de datos\n",
    "augmentation = CNN('resnet18',classes=list(train_set.columns),sample_duration=3.0) # Create the CNN\n",
    "augmentation.preprocessor.pipeline.bandpass.bypass = False\n",
    "augmentation.preprocessor.pipeline.time_mask.bypass = False\n",
    "augmentation.preprocessor.pipeline.frequency_mask.bypass = False\n",
    "augmentation.preprocessor.pipeline.add_noise.bypass = False\n",
    "augmentation.preprocessor.pipeline.random_affine.bypass = False\n",
    "augmentation.preprocessor.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4d73-XyE26e"
   },
   "outputs": [],
   "source": [
    "# Entrenamiento y evaluacion del modelo\n",
    "\n",
    "history = augmentation.train(train_df=train_set, validation_df=valid_set,save_path= folder +\"/Model\",\n",
    "                       epochs= 10,batch_size= 32, num_workers=0)\n",
    "\n",
    "plot_scatter(augmentation, title=\"Augmented model loss curve\")\n",
    "\n",
    "# Obten las predicciones y grafica los histogramas\n",
    "\n",
    "augmentation_test = augmentation.predict(testing_list)\n",
    "plot_testing_hist(augmentation_test,testing_df,\"Augmented model separability\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ai_-CopD8p0H"
   },
   "source": [
    "# 3.2 Cambia los hyperparametros (Tasa de aprendizaje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJMQrIG48p0H",
    "outputId": "5d0d8a85-4bf7-4c99-f21d-03c8cc690814"
   },
   "outputs": [],
   "source": [
    "# Modifica la tasa de aprendizaje\n",
    "learning = CNN('resnet18',classes=list(train_set.columns),sample_duration=3.0) # Create the CNN\n",
    "learning.optimizer_params['lr']=0.001\n",
    "learning.optimizer_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UrAi_tpj8p0H"
   },
   "outputs": [],
   "source": [
    "# Entrenamiento y evaluacion del modelo\n",
    "\n",
    "history = learning.train(train_df=train_set, validation_df=valid_set,save_path= folder +\"/Model\",\n",
    "                       epochs= 10,batch_size= 32, num_workers=0)\n",
    "\n",
    "plot_scatter(learning, title=\"Learning model loss curve\")\n",
    "\n",
    "# Obten las predicciones y grafica los histogramas\n",
    "\n",
    "learning_test = learning.predict(testing_list)\n",
    "plot_testing_hist(learning_test,testing_df,\"Learning model separability\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xQOkGGSECXw"
   },
   "source": [
    "# Evalua el modelo con cantos subrepresentados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G2EI22QwEIaI"
   },
   "outputs": [],
   "source": [
    "# Lista los archivos WAV en la carpeta de evaluacion\n",
    "testing_list_loca=sorted(glob(folder+'/Testing_location/*.wav'))\n",
    "# Final dataframe\n",
    "testing_df_under = pd.DataFrame({'paths': testing_list_loca, 'labels': testing_labels})\n",
    "\n",
    "under = load_model(folder + '/Model/best.model')\n",
    "\n",
    "test_under = under.predict(testing_list_loca)\n",
    "plot_testing_hist(test_under,testing_df_under,\"Baseline model separability (underrepresented)\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "opensoundscape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
