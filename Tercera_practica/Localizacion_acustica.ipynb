{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Localización acústica\n",
    "\n",
    "En esta practica vamos a mostrar el flujo de trabajo para hacer localizacion de una fuente de sonido a partir de ARUs sincronizadas, para ello es necesario:\n",
    "\n",
    "1) Despliegue de dispositivos de grabación sincronizables en el tiempo en ubicaciones estáticas y conocidas.\n",
    "\n",
    "2) Sincronizar las grabaciones.\n",
    "\n",
    "3) Etiquetado de las detecciones del sonido de interés en el audio.\n",
    "\n",
    "4) Estimación de los delays temporales de llegada (TDOA) del sonido de interés entre varios micrófonos.\n",
    "\n",
    "5) Localización de la fuente sonora a partir de los TDOA.\n",
    "\n",
    "6) Evaluar la fiabilidad de estas localizaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opensoundscape\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "from opensoundscape.localization import SynchronizedRecorderArray\n",
    "import pytz\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder=\"/Users/santiagoruiz/Documents/AI_Andes/Sesiones_practicas/Tercera_practica/Datos\"\n",
    "\n",
    "# Usa tu carpeta home o cualquier otra con permisos de escritura\n",
    "output_dir = Path.home() / folder \n",
    "tar_path = output_dir / \"localization_files.tar\"\n",
    "\n",
    "# Asegúrate de que el directorio existe\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Descargar\n",
    "subprocess.run(\n",
    "    [\"curl\", \"-L\", \n",
    "     \"https://drive.google.com/uc?export=download&id=1M4yKM8obqiY0FU2qEriINBDSWtQGqN8E\",\n",
    "     \"-o\", str(tar_path)]\n",
    ")\n",
    "\n",
    "# Descomprimir\n",
    "subprocess.run([\"tar\", \"-xzf\", str(tar_path)], cwd=str(output_dir))\n",
    "\n",
    "# Borrar el archivo .tar\n",
    "tar_path.unlink()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El primer tipo de archivo que necesitamos es una tabla con las coordenadas de 1 archivo de sonido por ARU. \n",
    "aru_coords = pd.read_csv(folder + \"/aru_coords.csv\", index_col=0) \n",
    "aru_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = SynchronizedRecorderArray(aru_coords)\n",
    "\n",
    "# Carga tabla con las detecciones (Obtenidas por cualquier tipo de detector)\n",
    "detections = pd.read_csv(folder + \"/detections.csv\")\n",
    "\n",
    "# Añade informacion de fecha, hora y zona horaria si el audio no lo contiene como metadatos\n",
    "local_timestamp = datetime(2022, 2, 7, 20, 0, 0) \n",
    "local_timezone = pytz.timezone(\"US/Eastern\")\n",
    "detections[\"start_timestamp\"] = [\n",
    "    local_timezone.localize(local_timestamp) + timedelta(seconds=s)\n",
    "    for s in detections[\"start_time\"]\n",
    "]\n",
    "\n",
    "#detections['file'] = folder + \"/\"+ detections['file']\n",
    "# Modifica el index de la tabla como multi-index \n",
    "detections = detections.set_index([\"file\", \"start_time\", \"end_time\", \"start_timestamp\"])\n",
    "\n",
    "detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localizacion de detecciones\n",
    "\n",
    "Antes de continuar es necesario definir 2 parametros:\n",
    "\n",
    "\n",
    "1) **min_n_receivers:** Número mínimo de receptores en los que debe detectarse un sonido para que se intente la localización. Debe ser al menos n+2 para localizar un punto en n dimensiones. Si tiene una cuadrícula de localización densa y espera que su sonido se escuche en más receptores, puede aumentar este número y puede mejorar la precisión de las estimaciones de localización.\n",
    "\n",
    "2) **max_receiver_dist+** Los TDOAs se estiman entre pares de receptores. Sólo se utilizarán para la estimación TDOAs los receptores que se encuentren a una distancia máxima entre sí. Si max_receiver_dist=100, entonces si 2 receptores >100 de distancia ambos contienen detecciones del mismo sonido, no se estimará un TDOA entre ellos. Esto es útil para separar múltiples sonidos simultáneos en diferentes ubicaciones si está desplegando un gran array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_n_receivers = 4  \n",
    "max_receiver_dist = 100 \n",
    "position_estimates = array.localize_detections(\n",
    "    detections, min_n_receivers=min_n_receivers, max_receiver_dist=max_receiver_dist\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El output final es una lista de objetos \"PositionEstimate\" que contienen los Sound events, veamos un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = position_estimates[0]\n",
    "print(f\"El tiempo de inicio de la detección es: {example.start_timestamp}\")\n",
    "print(f\"Esta es una deteccion de la clase/especie: {example.class_name}\")\n",
    "print(\n",
    "    f\"La duración de la ventana temporal en la que se detectó el sonido: {example.duration}\"\n",
    ")\n",
    "print(f\"La ubicacion estimada del sonido: {example.location_estimate}\")\n",
    "print(f\"La lista de ARUs en la que el sonido fue detectado: \\n{example.receiver_files}\")\n",
    "print(f\"Los TDOAs estimados: \\n{example.tdoas}\")\n",
    "print(f\"Los valores normalizados de cross-correlation: \\n{example.cc_maxs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(aru_coords[\"x\"], aru_coords[\"y\"], \"^\", label=\"ARU\")\n",
    "plt.scatter(\n",
    "    x=example.location_estimate[0],\n",
    "    y=example.location_estimate[1],\n",
    "    color=\"red\",\n",
    "    label=f\"{example.class_name}\",\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opensoundscape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
